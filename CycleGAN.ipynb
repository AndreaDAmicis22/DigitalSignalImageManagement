{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 21755,
          "databundleVersionId": 1475600,
          "sourceType": "competition"
        },
        {
          "sourceId": 1454962,
          "sourceType": "datasetVersion",
          "datasetId": 852942
        },
        {
          "sourceId": 1457269,
          "sourceType": "datasetVersion",
          "datasetId": 854438
        }
      ],
      "dockerImageVersionId": 30085,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8cQQuqUapzUe",
        "XXs-uZrcpzUg",
        "HJ-uvd2_pzUh",
        "mNT406DfpzUi",
        "j1-dKbwgpzUk",
        "MUIQxJw7pzUl",
        "glmx4AGUpzUl",
        "K0KjpXLSpzUm"
      ],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "8cQQuqUapzUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, json, PIL, shutil, re, imageio, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.backend as K\n",
        "import kagglehub\n",
        "from tensorflow.keras import Model, losses, optimizers\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from google.colab import drive\n",
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def seed_everything(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "SEED = 0\n",
        "seed_everything(SEED)"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T08:00:45.604882Z",
          "iopub.execute_input": "2025-02-14T08:00:45.605200Z",
          "iopub.status.idle": "2025-02-14T08:00:52.966294Z",
          "shell.execute_reply.started": "2025-02-14T08:00:45.605125Z",
          "shell.execute_reply": "2025-02-14T08:00:52.965177Z"
        },
        "id": "gL_erH2apzUe"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TPU configuration"
      ],
      "metadata": {
        "id": "Pf5VY3VapzUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(f'Running on TPU {tpu.master()}')\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "print(f'REPLICAS: {REPLICAS}')\n",
        "\"\"\"\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T08:00:52.971412Z",
          "iopub.execute_input": "2025-02-14T08:00:52.971734Z",
          "iopub.status.idle": "2025-02-14T08:00:52.985388Z",
          "shell.execute_reply.started": "2025-02-14T08:00:52.971702Z",
          "shell.execute_reply": "2025-02-14T08:00:52.984316Z"
        },
        "id": "YWieo-vUpzUf"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model parameters"
      ],
      "metadata": {
        "id": "XXs-uZrcpzUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HEIGHT = 256\n",
        "WIDTH = 256\n",
        "HEIGHT_RESIZE = 128\n",
        "WIDTH_RESIZE = 128\n",
        "CHANNELS = 3\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 150\n",
        "TRANSFORMER_BLOCKS = 6\n",
        "GENERATOR_LR = 2e-4\n",
        "DISCRIMINATOR_LR = 2e-4"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T08:01:04.008974Z",
          "iopub.execute_input": "2025-02-14T08:01:04.009319Z",
          "iopub.status.idle": "2025-02-14T08:01:04.013724Z",
          "shell.execute_reply.started": "2025-02-14T08:01:04.009290Z",
          "shell.execute_reply": "2025-02-14T08:01:04.012799Z"
        },
        "id": "meOoy_MApzUg"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "HJ-uvd2_pzUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/Digital Signal/Data/'\n",
        "\n",
        "MONET_FILENAMES = tf.io.gfile.glob(os.path.join(DATASET_PATH, 'monet_tfrec', 'monet*.tfrec'))\n",
        "PHOTO_FILENAMES = tf.io.gfile.glob(os.path.join(DATASET_PATH, 'photo_tfrec', 'photo*.tfrec'))\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\" ).search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "n_monet_samples = count_data_items(MONET_FILENAMES)\n",
        "n_photo_samples = count_data_items(PHOTO_FILENAMES)\n",
        "\n",
        "print(f'Monet TFRecord files: {len(MONET_FILENAMES)}')\n",
        "print(f'Monet image files: {n_monet_samples}')\n",
        "print(f'Photo TFRecord files: {len(PHOTO_FILENAMES)}')\n",
        "print(f'Photo image files: {n_photo_samples}')\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvklKf1ipzUh",
        "outputId": "ea8f691f-9986-4fd5-8f71-622efec0ba0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Monet TFRecord files: 5\n",
            "Monet image files: 300\n",
            "Photo TFRecord files: 20\n",
            "Photo image files: 7038\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentations\n",
        "\n",
        "Data augmentation for GANs should be done very carefully, especially for tasks similar to style transfer, if we apply transformations that can change too much the style of the data (e.g. brightness, contrast, saturation) it can cause the generator to do not efficiently learn the base style, so in this case, we are using only spatial transformations like, flips, rotates and crops."
      ],
      "metadata": {
        "id": "mNT406DfpzUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augment(image):\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "#     p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "\n",
        "\n",
        "#     # Random jitter\n",
        "#     image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    # 90º rotations\n",
        "    if p_rotate > .8:\n",
        "        image = tf.image.rot90(image, k=3) # rotate 270º\n",
        "    elif p_rotate > .6:\n",
        "        image = tf.image.rot90(image, k=2) # rotate 180º\n",
        "    elif p_rotate > .4:\n",
        "        image = tf.image.rot90(image, k=1) # rotate 90º\n",
        "\n",
        "    # Flips\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    if p_spatial > .75:\n",
        "        image = tf.image.transpose(image)\n",
        "\n",
        "#     # Crops\n",
        "#     if p_crop > .6: # random crop\n",
        "#         crop_size = tf.random.uniform([], int(HEIGHT*.7), HEIGHT, dtype=tf.int32)\n",
        "#         image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
        "#     elif p_crop > .2: # central crop\n",
        "#         if p_crop > .5:\n",
        "#             image = tf.image.central_crop(image, central_fraction=.7)\n",
        "#         elif p_crop > .35:\n",
        "#             image = tf.image.central_crop(image, central_fraction=.8)\n",
        "#         else:\n",
        "#             image = tf.image.central_crop(image, central_fraction=.9)\n",
        "\n",
        "    # Train on crops\n",
        "    image = tf.image.random_crop(image, size=[HEIGHT_RESIZE, WIDTH_RESIZE, CHANNELS])\n",
        "\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "7cSKCmn5pzUj"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliar functions"
      ],
      "metadata": {
        "id": "admw_VdPpzUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(img):\n",
        "    img = tf.cast(img, dtype=tf.float32)\n",
        "    # Map values in the range [-1, 1]\n",
        "    return (img / 127.5) - 1.0\n",
        "\n",
        "def decode_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
        "    image = tf.reshape(image, [HEIGHT, WIDTH, CHANNELS])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    tfrecord_format = {\n",
        "        'image':      tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    return image\n",
        "\n",
        "def load_dataset(filenames):\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        "\n",
        "def get_dataset(filenames, augment=None, repeat=True, shuffle=True, batch_size=1):\n",
        "    dataset = load_dataset(filenames)\n",
        "\n",
        "    if augment:\n",
        "        dataset = dataset.map(augment, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.map(normalize_img, num_parallel_calls=AUTO)\n",
        "    if repeat:\n",
        "        dataset = dataset.repeat()\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(512)\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def display_samples(ds, n_samples):\n",
        "    ds_iter = iter(ds)\n",
        "    for n_sample in range(n_samples):\n",
        "        example_sample = next(ds_iter)\n",
        "        plt.subplot(121)\n",
        "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "def display_generated_samples(ds, model, n_samples):\n",
        "    ds_iter = iter(ds)\n",
        "    for n_sample in range(n_samples):\n",
        "        example_sample = next(ds_iter)\n",
        "        generated_sample = model.predict(example_sample)\n",
        "\n",
        "        f = plt.figure(figsize=(12, 12))\n",
        "\n",
        "        plt.subplot(121)\n",
        "        plt.title('Input image')\n",
        "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(122)\n",
        "        plt.title('Generated image')\n",
        "        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "def evaluate_cycle(ds, generator_a, generator_b, n_samples=1):\n",
        "    fig, axes = plt.subplots(n_samples, 3, figsize=(22, (n_samples*6)))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    ds_iter = iter(ds)\n",
        "    for n_sample in range(n_samples):\n",
        "        idx = n_sample*3\n",
        "        example_sample = next(ds_iter)\n",
        "        generated_a_sample = generator_a.predict(example_sample)\n",
        "        generated_b_sample = generator_b.predict(generated_a_sample)\n",
        "\n",
        "        axes[idx].set_title('Input image', fontsize=18)\n",
        "        axes[idx].imshow(example_sample[0] * 0.5 + 0.5)\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "        axes[idx+1].set_title('Generated image', fontsize=18)\n",
        "        axes[idx+1].imshow(generated_a_sample[0] * 0.5 + 0.5)\n",
        "        axes[idx+1].axis('off')\n",
        "\n",
        "        axes[idx+2].set_title('Cycled image', fontsize=18)\n",
        "        axes[idx+2].imshow(generated_b_sample[0] * 0.5 + 0.5)\n",
        "        axes[idx+2].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def create_gif(images_path, gif_path):\n",
        "    images = []\n",
        "    filenames = glob.glob(images_path)\n",
        "    filenames.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
        "    for epoch, filename in enumerate(filenames):\n",
        "        img = PIL.ImageDraw.Image.open(filename)\n",
        "        ImageDraw.Draw(img).text((0, 0),  # Coordinates\n",
        "                                 f'Epoch {epoch+1}')\n",
        "        images.append(img)\n",
        "    imageio.mimsave(gif_path, images, fps=2) # Save gif\n",
        "\n",
        "def predict_and_save(input_ds, generator_model, output_path):\n",
        "    i = 1\n",
        "    for img in input_ds:\n",
        "        prediction = generator_model(img, training=False)[0].numpy() # make predition\n",
        "        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)   # re-scale\n",
        "        im = PIL.Image.fromarray(prediction)\n",
        "        im.save(f'{output_path}{str(i)}.jpg')\n",
        "        i += 1"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "nYuHZFvdpzUk"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliar functions (model)\n",
        "\n",
        "Here we the building blocks of our models:\n",
        "- Encoder block: Apply convolutional filters while also reducing data resolution and increasing features.\n",
        "- Decoder block: Apply convolutional filters while also increasing data resolution and decreasing features.\n",
        "- Transformer block: Apply convolutional filters to find relevant data patterns and keeps features constant."
      ],
      "metadata": {
        "id": "qXs1Ej0KpzUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_initializer = tf.random_normal_initializer(mean=0.0, stddev=0.02)\n",
        "gamma_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "def encoder_block(input_layer, filters, size=3, strides=2, apply_instancenorm=True, activation=L.ReLU(), name='block_x'):\n",
        "    block = L.Conv2D(filters, size,\n",
        "                     strides=strides,\n",
        "                     padding='same',\n",
        "                     use_bias=False,\n",
        "                     kernel_initializer=conv_initializer,\n",
        "                     name=f'encoder_{name}')(input_layer)\n",
        "\n",
        "    if apply_instancenorm:\n",
        "        block = tf.keras.layers.LayerNormalization(gamma_initializer=gamma_initializer)(block)\n",
        "\n",
        "    block = activation(block)\n",
        "\n",
        "    return block\n",
        "\n",
        "def transformer_block(input_layer, size=3, strides=1, name='block_x'):\n",
        "    filters = input_layer.shape[-1]\n",
        "\n",
        "    block = L.Conv2D(filters, size, strides=strides, padding='same', use_bias=False,\n",
        "                     kernel_initializer=conv_initializer, name=f'transformer_{name}_1')(input_layer)\n",
        "#     block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n",
        "    block = L.ReLU()(block)\n",
        "\n",
        "    block = L.Conv2D(filters, size, strides=strides, padding='same', use_bias=False,\n",
        "                     kernel_initializer=conv_initializer, name=f'transformer_{name}_2')(block)\n",
        "#     block = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(block)\n",
        "\n",
        "    block = L.Add()([block, input_layer])\n",
        "\n",
        "    return block\n",
        "\n",
        "def decoder_block(input_layer, filters, size=3, strides=2, apply_instancenorm=True, name='block_x'):\n",
        "    block = L.Conv2DTranspose(filters, size,\n",
        "                              strides=strides,\n",
        "                              padding='same',\n",
        "                              use_bias=False,\n",
        "                              kernel_initializer=conv_initializer,\n",
        "                              name=f'decoder_{name}')(input_layer)\n",
        "\n",
        "    if apply_instancenorm:\n",
        "        block = tf.keras.layers.LayerNormalization(gamma_initializer=gamma_initializer)(block)\n",
        "\n",
        "    block = L.ReLU()(block)\n",
        "\n",
        "    return block\n",
        "\n",
        "# Resized convolution\n",
        "def decoder_rc_block(input_layer, filters, size=3, strides=1, apply_instancenorm=True, name='block_x'):\n",
        "    block = tf.image.resize(images=input_layer, method='bilinear',\n",
        "                            size=(input_layer.shape[1]*2, input_layer.shape[2]*2))\n",
        "\n",
        "#     block = tf.pad(block, [[0, 0], [1, 1], [1, 1], [0, 0]], \"SYMMETRIC\") # Works only with GPU\n",
        "#     block = L.Conv2D(filters, size, strides=strides, padding='valid', use_bias=False, # Works only with GPU\n",
        "    block = L.Conv2D(filters, size,\n",
        "                     strides=strides,\n",
        "                     padding='same',\n",
        "                     use_bias=False,\n",
        "                     kernel_initializer=conv_initializer,\n",
        "                     name=f'decoder_{name}')(block)\n",
        "\n",
        "    if apply_instancenorm:\n",
        "        block = tf.keras.layers.LayerNormalization(gamma_initializer=gamma_initializer)(block)\n",
        "\n",
        "    block = L.ReLU()(block)\n",
        "\n",
        "    return block"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "1FKzfBw4pzUk"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator model\n",
        "\n",
        "The `generator` is responsible for generating images from a specific domain. `CycleGAN` architecture has two generators, in this context we will have one `generator` that will take `photos` and generate `Monet paints`, and the other `generator` will take `Monet paintings` and generate `photos`.\n",
        "\n",
        "Below, we have the architecture of the original `CycleGAN` `generator`, ours have some changes to improve performance on this task.\n",
        "\n",
        "<center><img src='https://github.com/dimitreOliveira/MachineLearning/blob/master/Kaggle/I%E2%80%99m%20Something%20of%20a%20Painter%20Myself/generator_architecture.png?raw=true' height=250></center>"
      ],
      "metadata": {
        "id": "j1-dKbwgpzUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_fn(height=HEIGHT, width=WIDTH, channels=CHANNELS, transformer_blocks=TRANSFORMER_BLOCKS):\n",
        "    OUTPUT_CHANNELS = 3\n",
        "    inputs = L.Input(shape=[height, width, channels], name='input_image')\n",
        "\n",
        "    # Encoder\n",
        "    enc_1 = encoder_block(inputs, 64,  7, 1, apply_instancenorm=False, activation=L.ReLU(), name='block_1') # (bs, 256, 256, 64)\n",
        "    enc_2 = encoder_block(enc_1, 128, 3, 2, apply_instancenorm=True, activation=L.ReLU(), name='block_2')   # (bs, 128, 128, 128)\n",
        "    enc_3 = encoder_block(enc_2, 256, 3, 2, apply_instancenorm=True, activation=L.ReLU(), name='block_3')   # (bs, 64, 64, 256)\n",
        "\n",
        "    # Transformer\n",
        "    x = enc_3\n",
        "    for n in range(transformer_blocks):\n",
        "        x = transformer_block(x, 3, 1, name=f'block_{n+1}') # (bs, 64, 64, 256)\n",
        "\n",
        "    # Decoder\n",
        "    x_skip = L.Concatenate(name='enc_dec_skip_1')([x, enc_3]) # encoder - decoder skip connection\n",
        "\n",
        "    dec_1 = decoder_block(x_skip, 128, 3, 2, apply_instancenorm=True, name='block_1') # (bs, 128, 128, 128)\n",
        "    x_skip = L.Concatenate(name='enc_dec_skip_2')([dec_1, enc_2]) # encoder - decoder skip connection\n",
        "\n",
        "    dec_2 = decoder_block(x_skip, 64,  3, 2, apply_instancenorm=True, name='block_2') # (bs, 256, 256, 64)\n",
        "    x_skip = L.Concatenate(name='enc_dec_skip_3')([dec_2, enc_1]) # encoder - decoder skip connection\n",
        "\n",
        "    outputs = last = L.Conv2D(OUTPUT_CHANNELS, 7,\n",
        "                              strides=1, padding='same',\n",
        "                              kernel_initializer=conv_initializer,\n",
        "                              use_bias=False,\n",
        "                              activation='tanh',\n",
        "                              name='decoder_output_block')(x_skip) # (bs, 256, 256, 3)\n",
        "\n",
        "    generator = Model(inputs, outputs)\n",
        "\n",
        "    return generator\n",
        "\n",
        "sample_generator = generator_fn()\n",
        "sample_generator.summary()"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MArz_PjqpzUl",
        "outputId": "2382edd4-af6b-4d9e-f35e-f1016ef60525"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_image (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_block_1 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m9,408\u001b[0m │ input_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ encoder_block_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_block_2 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,728\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m256\u001b[0m │ encoder_block_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_block_3 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m294,912\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ encoder_block_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_1_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_1_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_1_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_1_2… │\n",
              "│                           │                        │                │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_2_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_2_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_2_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_2_2… │\n",
              "│                           │                        │                │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_3_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_3_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_3_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_3_2… │\n",
              "│                           │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_4_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_4_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_4_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_4_2… │\n",
              "│                           │                        │                │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_5_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_5_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_5_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_5_2… │\n",
              "│                           │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_6_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_6_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_6_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ transformer_block_6_2… │\n",
              "│                           │                        │                │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ enc_dec_skip_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_block_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m589,824\u001b[0m │ enc_dec_skip_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m256\u001b[0m │ decoder_block_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ enc_dec_skip_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_block_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m147,456\u001b[0m │ enc_dec_skip_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ decoder_block_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ enc_dec_skip_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_output_block      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │         \u001b[38;5;34m18,816\u001b[0m │ enc_dec_skip_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │ input_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_block_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ encoder_block_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">294,912</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ encoder_block_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_1_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_1_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_1_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_1_2… │\n",
              "│                           │                        │                │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_2_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_2_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_2_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_2_2… │\n",
              "│                           │                        │                │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_3_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_3_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_3_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_3_2… │\n",
              "│                           │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_4_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_4_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_4_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_4_2… │\n",
              "│                           │                        │                │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_5_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_5_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_5_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_5_2… │\n",
              "│                           │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_6_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_6_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_6_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_6_2… │\n",
              "│                           │                        │                │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ enc_dec_skip_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_block_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ enc_dec_skip_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ decoder_block_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ enc_dec_skip_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_block_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ enc_dec_skip_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ decoder_block_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ enc_dec_skip_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_output_block      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,816</span> │ enc_dec_skip_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,213,184\u001b[0m (31.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,213,184</span> (31.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,213,184\u001b[0m (31.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,213,184</span> (31.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator model\n",
        "\n",
        "\n",
        "The `discriminator` is responsible for differentiating real images from images that have been generated by a `generator` model.\n",
        "\n",
        "Bellow, we have the architecture of the original `CycleGAN` `discriminator`, again, ours have some changes to improve performance on this task.\n",
        "\n",
        "<center><img src='https://github.com/dimitreOliveira/MachineLearning/blob/master/Kaggle/I%E2%80%99m%20Something%20of%20a%20Painter%20Myself/discriminator_architecture.png?raw=true' height=550, width=550></center>"
      ],
      "metadata": {
        "id": "MUIQxJw7pzUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_fn(height=HEIGHT, width=WIDTH, channels=CHANNELS):\n",
        "    inputs = L.Input(shape=[height, width, channels], name='input_image')\n",
        "    #inputs_patch = L.experimental.preprocessing.RandomCrop(height=70, width=70, name='input_image_patch')(inputs) # Works only with GPU\n",
        "\n",
        "    # Encoder\n",
        "    x = encoder_block(inputs, 64,  4, 2, apply_instancenorm=False, activation=L.LeakyReLU(0.2), name='block_1') # (bs, 128, 128, 64)\n",
        "    x = encoder_block(x, 128, 4, 2, apply_instancenorm=True, activation=L.LeakyReLU(0.2), name='block_2')       # (bs, 64, 64, 128)\n",
        "    x = encoder_block(x, 256, 4, 2, apply_instancenorm=True, activation=L.LeakyReLU(0.2), name='block_3')       # (bs, 32, 32, 256)\n",
        "    x = encoder_block(x, 512, 4, 1, apply_instancenorm=True, activation=L.LeakyReLU(0.2), name='block_4')       # (bs, 32, 32, 512)\n",
        "\n",
        "    outputs = L.Conv2D(1, 4, strides=1, padding='valid', kernel_initializer=conv_initializer)(x)                # (bs, 29, 29, 1)\n",
        "\n",
        "    discriminator = Model(inputs, outputs)\n",
        "\n",
        "    return discriminator\n",
        "\n",
        "\n",
        "sample_discriminator = discriminator_fn()\n",
        "sample_discriminator.summary()"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "Q7phjGPApzUl",
        "outputId": "644f1659-3df0-4c6d-dc03-04304becc93d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_image (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m3,072\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m131,072\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_3 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m524,288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_4 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,097,152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │           \u001b[38;5;34m8,193\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ encoder_block_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,765,569\u001b[0m (10.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,765,569</span> (10.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,765,569\u001b[0m (10.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,765,569</span> (10.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build model (CycleGAN)"
      ],
      "metadata": {
        "id": "glmx4AGUpzUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#with strategy.scope():\n",
        "monet_generator = generator_fn(height=None, width=None, transformer_blocks=TRANSFORMER_BLOCKS) # transforms photos to Monet-esque paintings\n",
        "photo_generator = generator_fn(height=None, width=None, transformer_blocks=TRANSFORMER_BLOCKS) # transforms Monet paintings to be more like photos\n",
        "\n",
        "monet_discriminator = discriminator_fn(height=None, width=None) # differentiates real Monet paintings and generated Monet paintings\n",
        "photo_discriminator = discriminator_fn(height=None, width=None) # differentiates real photos and generated photos\n",
        "\n",
        "\n",
        "class CycleGan(Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        monet_generator,\n",
        "        photo_generator,\n",
        "        monet_discriminator,\n",
        "        photo_discriminator,\n",
        "        lambda_cycle=10,\n",
        "    ):\n",
        "        super(CycleGan, self).__init__()\n",
        "        self.m_gen = monet_generator\n",
        "        self.p_gen = photo_generator\n",
        "        self.m_disc = monet_discriminator\n",
        "        self.p_disc = photo_discriminator\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        m_gen_optimizer,\n",
        "        p_gen_optimizer,\n",
        "        m_disc_optimizer,\n",
        "        p_disc_optimizer,\n",
        "        gen_loss_fn,\n",
        "        disc_loss_fn,\n",
        "        cycle_loss_fn,\n",
        "        identity_loss_fn\n",
        "    ):\n",
        "        super(CycleGan, self).compile()\n",
        "        self.m_gen_optimizer = m_gen_optimizer\n",
        "        self.p_gen_optimizer = p_gen_optimizer\n",
        "        self.m_disc_optimizer = m_disc_optimizer\n",
        "        self.p_disc_optimizer = p_disc_optimizer\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "        self.disc_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = cycle_loss_fn\n",
        "        self.identity_loss_fn = identity_loss_fn\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        real_monet, real_photo = batch_data\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # photo to monet back to photo\n",
        "            fake_monet = self.m_gen(real_photo, training=True)\n",
        "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
        "\n",
        "            # monet to photo back to monet\n",
        "            fake_photo = self.p_gen(real_monet, training=True)\n",
        "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
        "\n",
        "            # generating itself\n",
        "            same_monet = self.m_gen(real_monet, training=True)\n",
        "            same_photo = self.p_gen(real_photo, training=True)\n",
        "\n",
        "            # discriminator used to check, inputing real images\n",
        "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
        "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
        "\n",
        "            # discriminator used to check, inputing fake images\n",
        "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
        "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
        "\n",
        "            # evaluates generator loss\n",
        "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
        "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
        "\n",
        "            # evaluates total cycle consistency loss\n",
        "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
        "\n",
        "            # evaluates total generator loss\n",
        "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
        "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
        "\n",
        "            # evaluates discriminator loss\n",
        "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
        "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
        "\n",
        "        # Calculate the gradients for generator and discriminator\n",
        "        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n",
        "                                                  self.m_gen.trainable_variables)\n",
        "        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n",
        "                                                  self.p_gen.trainable_variables)\n",
        "\n",
        "        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n",
        "                                                      self.m_disc.trainable_variables)\n",
        "        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n",
        "                                                      self.p_disc.trainable_variables)\n",
        "\n",
        "        # Apply the gradients to the optimizer\n",
        "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n",
        "                                                 self.m_gen.trainable_variables))\n",
        "\n",
        "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n",
        "                                                 self.p_gen.trainable_variables))\n",
        "\n",
        "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n",
        "                                                  self.m_disc.trainable_variables))\n",
        "\n",
        "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n",
        "                                                  self.p_disc.trainable_variables))\n",
        "\n",
        "        return {'monet_gen_loss': total_monet_gen_loss,\n",
        "                'photo_gen_loss': total_photo_gen_loss,\n",
        "                'monet_disc_loss': monet_disc_loss,\n",
        "                'photo_disc_loss': photo_disc_loss\n",
        "               }"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "rXeUb2o1pzUl"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss functions"
      ],
      "metadata": {
        "id": "K0KjpXLSpzUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#with strategy.scope():\n",
        "    # Discriminator loss {0: fake, 1: real} (The discriminator loss outputs the average of the real and generated loss)\n",
        "def discriminator_loss(real, generated):\n",
        "    real_loss = losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.ones_like(real), real)\n",
        "\n",
        "    generated_loss = losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
        "\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_disc_loss * 0.5\n",
        "\n",
        "    # Generator loss\n",
        "def generator_loss(generated):\n",
        "    return losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.ones_like(generated), generated)\n",
        "\n",
        "\n",
        "    # Cycle consistency loss (measures if original photo and the twice transformed photo to be similar to one another)\n",
        "    #with strategy.scope():\n",
        "def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
        "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "\n",
        "    return LAMBDA * loss1\n",
        "\n",
        "    # Identity loss (compares the image with its generator (i.e. photo with photo generator))\n",
        "    #with strategy.scope():\n",
        "def identity_loss(real_image, same_image, LAMBDA):\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "    return LAMBDA * 0.5 * loss"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "eRj-G-zrpzUm"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning rate schedule\n",
        "\n",
        "The original `CycleGAN` implementation used a `constant learning rate schedule with a linear decay`, I also found that the linear decay phase seems to be good at making the model more stable at the last epochs, you can check how the `generator` changes in a more conservative rate by the end looking at the `gif` images by the end."
      ],
      "metadata": {
        "id": "9a059Ld_pzUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def linear_schedule_with_warmup(step):\n",
        "    \"\"\" Create a schedule with a learning rate that decreases linearly after\n",
        "    linearly increasing during a warmup period.\n",
        "    \"\"\"\n",
        "    lr_start   = 2e-4\n",
        "    lr_max     = 2e-4\n",
        "    lr_min     = 0.\n",
        "\n",
        "    steps_per_epoch = int(max(n_monet_samples, n_photo_samples)//BATCH_SIZE)\n",
        "    total_steps = EPOCHS * steps_per_epoch\n",
        "    warmup_steps = 1\n",
        "    hold_max_steps = total_steps * 0.8\n",
        "\n",
        "    if step < warmup_steps:\n",
        "        lr = (lr_max - lr_start) / warmup_steps * step + lr_start\n",
        "    elif step < warmup_steps + hold_max_steps:\n",
        "        lr = lr_max\n",
        "    else:\n",
        "        lr = lr_max * ((total_steps - step) / (total_steps - warmup_steps - hold_max_steps))\n",
        "        if lr_min is not None:\n",
        "            lr = tf.math.maximum(lr_min, lr)\n",
        "\n",
        "    return lr\n",
        "\n",
        "steps_per_epoch = int(max(n_monet_samples, n_photo_samples)//BATCH_SIZE)\n",
        "total_steps = EPOCHS * steps_per_epoch\n",
        "rng = [i for i in range(0, total_steps, 50)]\n",
        "y = [linear_schedule_with_warmup(x) for x in rng]\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(20, 6))\n",
        "plt.plot(rng, y)\n",
        "print(f'{EPOCHS} total epochs and {steps_per_epoch} steps per epoch')\n",
        "print(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "S6GuzkwrpzUm",
        "outputId": "5d062f50-a736-4709-e799-ae67601f91f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function linear_schedule_with_warmup at 0x7f008856c360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function linear_schedule_with_warmup at 0x7f008856c360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 total epochs and 439 steps per epoch\n",
            "Learning rate schedule: 0.0002 to 0.0002 to 7.59e-07\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "0iRFWeWbpzUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#with strategy.scope():\n",
        "# Create generators\n",
        "lr_monet_gen = lambda: linear_schedule_with_warmup(tf.cast(monet_generator_optimizer.iterations, tf.float32))\n",
        "lr_photo_gen = lambda: linear_schedule_with_warmup(tf.cast(photo_generator_optimizer.iterations, tf.float32))\n",
        "\n",
        "monet_generator_optimizer = optimizers.Adam(learning_rate=lr_monet_gen, beta_1=0.5)\n",
        "photo_generator_optimizer = optimizers.Adam(learning_rate=lr_photo_gen, beta_1=0.5)\n",
        "\n",
        "# Create discriminators\n",
        "lr_monet_disc = lambda: linear_schedule_with_warmup(tf.cast(monet_discriminator_optimizer.iterations, tf.float32))\n",
        "lr_photo_disc = lambda: linear_schedule_with_warmup(tf.cast(photo_discriminator_optimizer.iterations, tf.float32))\n",
        "\n",
        "monet_discriminator_optimizer = optimizers.Adam(learning_rate=lr_monet_disc, beta_1=0.5)\n",
        "photo_discriminator_optimizer = optimizers.Adam(learning_rate=lr_photo_disc, beta_1=0.5)\n",
        "\n",
        "\n",
        "# Create GAN\n",
        "gan_model = CycleGan(monet_generator, photo_generator,\n",
        "                     monet_discriminator, photo_discriminator)\n",
        "\n",
        "gan_model.compile(m_gen_optimizer=monet_generator_optimizer,\n",
        "                  p_gen_optimizer=photo_generator_optimizer,\n",
        "                  m_disc_optimizer=monet_discriminator_optimizer,\n",
        "                  p_disc_optimizer=photo_discriminator_optimizer,\n",
        "                  gen_loss_fn=generator_loss,\n",
        "                  disc_loss_fn=discriminator_loss,\n",
        "                  cycle_loss_fn=calc_cycle_loss,\n",
        "                  identity_loss_fn=identity_loss)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "8SwAEArJpzUm"
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "monet_ds = get_dataset(MONET_FILENAMES, augment=data_augment, batch_size=BATCH_SIZE)\n",
        "photo_ds = get_dataset(PHOTO_FILENAMES, augment=data_augment, batch_size=BATCH_SIZE)\n",
        "gan_ds = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
        "\n",
        "photo_ds_eval = get_dataset(PHOTO_FILENAMES, repeat=False, shuffle=False, batch_size=1)\n",
        "monet_ds_eval = get_dataset(MONET_FILENAMES, repeat=False, shuffle=False, batch_size=1)\n",
        "\n",
        "# Callbacks\n",
        "class GANMonitor(Callback):\n",
        "    \"\"\"A callback to generate and save images after each epoch\"\"\"\n",
        "\n",
        "    def __init__(self, num_img=1, monet_path='monet', photo_path='photo'):\n",
        "        self.num_img = num_img\n",
        "        self.monet_path = monet_path\n",
        "        self.photo_path = photo_path\n",
        "        # Create directories to save the generate images\n",
        "        if not os.path.exists(self.monet_path):\n",
        "            os.makedirs(self.monet_path)\n",
        "        if not os.path.exists(self.photo_path):\n",
        "            os.makedirs(self.photo_path)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Monet generated images\n",
        "        for i, img in enumerate(photo_ds_eval.take(self.num_img)):\n",
        "            prediction = monet_generator(img, training=False)[0].numpy()\n",
        "            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
        "            prediction = PIL.Image.fromarray(prediction)\n",
        "            prediction.save(f'{self.monet_path}/generated_{i}_{epoch+1}.png')\n",
        "\n",
        "        # Photo generated images\n",
        "        for i, img in enumerate(monet_ds_eval.take(self.num_img)):\n",
        "            prediction = photo_generator(img, training=False)[0].numpy()\n",
        "            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
        "            prediction = PIL.Image.fromarray(prediction)\n",
        "            prediction.save(f'{self.photo_path}/generated_{i}_{epoch+1}.png')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "A7vpNhUypzUm"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "history = gan_model.fit(gan_ds,\n",
        "                        epochs=EPOCHS,\n",
        "                        callbacks=[GANMonitor()],\n",
        "                        steps_per_epoch=(max(n_monet_samples, n_photo_samples)//BATCH_SIZE),\n",
        "                        verbose=2).history"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "fiedfMbQpzUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea170110-27dc-41a2-d75e-a55fbd09cc90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "439/439 - 430s - 979ms/step - monet_disc_loss: 0.6206 - monet_gen_loss: 2.8872 - photo_disc_loss: 0.5089 - photo_gen_loss: 3.0528\n",
            "Epoch 2/150\n",
            "439/439 - 379s - 863ms/step - monet_disc_loss: 0.6819 - monet_gen_loss: 2.3363 - photo_disc_loss: 0.6816 - photo_gen_loss: 2.6722\n",
            "Epoch 3/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.5074 - monet_gen_loss: 2.4575 - photo_disc_loss: 0.5619 - photo_gen_loss: 3.0049\n",
            "Epoch 4/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.5864 - monet_gen_loss: 2.5903 - photo_disc_loss: 0.5709 - photo_gen_loss: 2.5547\n",
            "Epoch 5/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.6329 - monet_gen_loss: 2.4119 - photo_disc_loss: 0.6081 - photo_gen_loss: 2.4195\n",
            "Epoch 6/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.6678 - monet_gen_loss: 2.2016 - photo_disc_loss: 0.5801 - photo_gen_loss: 2.1132\n",
            "Epoch 7/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.6689 - monet_gen_loss: 2.2776 - photo_disc_loss: 0.5784 - photo_gen_loss: 2.5156\n",
            "Epoch 8/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.6379 - monet_gen_loss: 1.9709 - photo_disc_loss: 0.5970 - photo_gen_loss: 2.3673\n",
            "Epoch 9/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.6611 - monet_gen_loss: 2.2880 - photo_disc_loss: 0.6712 - photo_gen_loss: 2.2857\n",
            "Epoch 10/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.5227 - monet_gen_loss: 2.3857 - photo_disc_loss: 0.5622 - photo_gen_loss: 2.2019\n",
            "Epoch 11/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.6813 - monet_gen_loss: 2.4225 - photo_disc_loss: 0.6117 - photo_gen_loss: 2.5015\n",
            "Epoch 12/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.5710 - monet_gen_loss: 2.7052 - photo_disc_loss: 0.4932 - photo_gen_loss: 2.4599\n",
            "Epoch 13/150\n",
            "439/439 - 379s - 863ms/step - monet_disc_loss: 0.5226 - monet_gen_loss: 2.3067 - photo_disc_loss: 0.5630 - photo_gen_loss: 2.7230\n",
            "Epoch 14/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.5701 - monet_gen_loss: 2.3745 - photo_disc_loss: 0.5172 - photo_gen_loss: 2.3020\n",
            "Epoch 15/150\n",
            "439/439 - 378s - 861ms/step - monet_disc_loss: 0.6100 - monet_gen_loss: 2.5877 - photo_disc_loss: 0.5656 - photo_gen_loss: 2.4808\n",
            "Epoch 16/150\n",
            "439/439 - 378s - 861ms/step - monet_disc_loss: 0.5903 - monet_gen_loss: 2.5039 - photo_disc_loss: 0.4324 - photo_gen_loss: 2.6676\n",
            "Epoch 17/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.7578 - monet_gen_loss: 2.4456 - photo_disc_loss: 0.6029 - photo_gen_loss: 2.5367\n",
            "Epoch 18/150\n",
            "439/439 - 378s - 862ms/step - monet_disc_loss: 0.5822 - monet_gen_loss: 2.1568 - photo_disc_loss: 0.4907 - photo_gen_loss: 2.4360\n",
            "Epoch 19/150\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the generators progress at each epoch by creating a `gif` that is a generated image at each epoch.\n",
        "\n",
        "## Monet generation GIF"
      ],
      "metadata": {
        "id": "AbZru9jZpzUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Got the idea from https://www.kaggle.com/matkneky/monet-cyclegan-trials\n",
        "# Create GIFs\n",
        "create_gif('/kaggle/working/monet/*.png', 'monet.gif') # Create monet gif"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "fi3KuBQBpzUo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='monet.gif' width=350>"
      ],
      "metadata": {
        "id": "BCktLwckpzUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Photo generation GIF"
      ],
      "metadata": {
        "id": "iBpIFdFjpzUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_gif('/kaggle/working/photo/*.png', 'photo.gif') # Create photo gif"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "nsZGnEGapzUo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='photo.gif' width=350>"
      ],
      "metadata": {
        "id": "6fOL3jjapzUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating generator models\n",
        "\n",
        "Here we are going to evaluate the generator models including how good is the generator cycle, this means that we will get a photo to generate a Monet picture from it, then use the generated picture to generate the original photo.\n",
        "\n",
        "## Photo (input) -> Monet (generated) -> Photo (generated)"
      ],
      "metadata": {
        "id": "KrYJGkAmpzUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_cycle(photo_ds_eval.take(2), monet_generator, photo_generator, n_samples=2)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "22NrQjzIpzUp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will do the same process but starting with a Monet picture.\n",
        "\n",
        "## Monet (input) -> Photo (generated) -> Monet (generated)"
      ],
      "metadata": {
        "id": "70qZOy3lpzUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_cycle(monet_ds_eval.take(2), photo_generator, monet_generator, n_samples=2)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "bjlmTMaRpzUp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize predictions\n",
        "\n",
        "A common issue with images generated by GANs is that the often show some undisered artifacts, a very common on is known as \"[checkerboard artifacts](https://distill.pub/2016/deconv-checkerboard/)\", a good practice is to inspect some of the images to see its quality and if some of these undisered artifacts are present."
      ],
      "metadata": {
        "id": "2J08J9FLpzUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_generated_samples(photo_ds_eval.take(8), monet_generator, 8)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "lme7eXknpzUp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "0QsmYXAjpzUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "os.makedirs('../images/') # Create folder to save generated images\n",
        "predict_and_save(photo_ds_eval, monet_generator, '../images/')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "enGDAw3gpzUp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission file"
      ],
      "metadata": {
        "id": "sNurZW9JpzUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('/kaggle/working/images/', 'zip', '../images')\n",
        "\n",
        "print(f\"Generated samples: {len([name for name in os.listdir('../images/') if os.path.isfile(os.path.join('../images/', name))])}\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "q2RB71nGpzUq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output models"
      ],
      "metadata": {
        "id": "d4LzNkcopzUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monet_generator.save('monet_generator.weights.h5')\n",
        "photo_generator.save('photo_generator.weights.h5')\n",
        "monet_discriminator.save('monet_discriminator.weights.h5')\n",
        "photo_discriminator.save('photo_discriminator.weights.h5')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "WFBiNEt3pzUq"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}